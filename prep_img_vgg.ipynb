{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import glob\n",
    "from pickle import dump, load\n",
    "from time import time\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.merge import add\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename,'r')\n",
    "    text = file.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pre-defined list of photo identifiers\n",
    "def load_set(filename):\n",
    "    doc = load_doc(filename)\n",
    "    dataset = list()\n",
    "    # process line by line\n",
    "    for line in doc.split('\\n'):\n",
    "        # skip empty lines\n",
    "        if len(line) < 1:\n",
    "            continue\n",
    "        # get the image identifier\n",
    "        identifier = line.split('.')[0]\n",
    "        dataset.append(identifier)\n",
    "    return (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Dataset: 6000\n"
     ]
    }
   ],
   "source": [
    "# load training dataset (6K)\n",
    "train_text_filename = 'Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "train = load_set(train_text_filename)\n",
    "print('Train-Dataset: %d' % len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading full dataset image name  \n",
    "image_names = []\n",
    "images_directory= 'Flickr8k_Dataset'\n",
    "for name in listdir(images_directory):\n",
    "    image_names.append(images_directory+'/'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "train_names = []\n",
    "# check and load training images\n",
    "for i in image_names:\n",
    "    i=i.split('/')\n",
    "    \n",
    "    if i[-1].split('.')[0] in train:\n",
    "        train_names.append('/'.join(i))\n",
    "print(len(train_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Dataset: 1000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load test dataset images\n",
    "# load training dataset (6K)\n",
    "test_text_filename = 'Flickr8k_text/Flickr_8k.testImages.txt'\n",
    "test = load_set(test_text_filename)\n",
    "print('Test-Dataset: %d' % len(test),'\\n')\n",
    "\n",
    "test_names = []\n",
    "# check and load testing images\n",
    "for i in image_names:\n",
    "    i=i.split('/')\n",
    "    \n",
    "    if i[-1].split('.')[0] in test:\n",
    "        test_names.append('/'.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path):\n",
    "    # Convert all the images to size 299x299 as expected by the inception v3 model\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    # Convert PIL image to numpy array of 3-dimensions\n",
    "    x = img_to_array(img)\n",
    "    # Add one more dimension\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    # preprocess the images using preprocess_input() from inception module\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hemanth/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Load the inception v3 model\n",
    "model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model, by removing the last layer (output layer) from the inception v3\n",
    "model_new = Model(model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a given image into a vector of size (2048, )\n",
    "def encode(image):\n",
    "    image = preprocess(image) # preprocess the image\n",
    "    fea_vec = model_new.predict(image,verbose=0) # Get the encoding vector for the image\n",
    "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1]) # reshape from (1, 2048) to (2048, )\n",
    "    return fea_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images encoded : 6000/6000Time taken in seconds = 235.5976688861847\n"
     ]
    }
   ],
   "source": [
    "# Call the funtion to encode all the train images\n",
    "start = time()\n",
    "a=1\n",
    "encoding_train = {}\n",
    "for img in train_names:\n",
    "    encoding_train[img.split('/')[-1]] = encode(img)\n",
    "    sys.stdout.write('\\r'+'Images encoded : '+str(a)+'/6000')\n",
    "    sys.stdout.flush()\n",
    "    a=a+1\n",
    "print(\"Time taken in seconds =\", time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the bottleneck train features to disk\n",
    "with open(\"encoded_train_images.pkl\", \"wb\") as encoded_pickle:\n",
    "   dump(encoding_train, encoded_pickle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape of the image features are:  4096\n"
     ]
    }
   ],
   "source": [
    "print('output shape of the image features are: ',len(list(encoding_train.items())[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images encoded : 1000/1000\n",
      "Time taken in seconds = 38.65292692184448\n"
     ]
    }
   ],
   "source": [
    "# Call the funtion to encode all the test images - Execute this only once\n",
    "start = time()\n",
    "encoding_test = {}\n",
    "a=1\n",
    "for img in test_names:\n",
    "    encoding_test[img.split('/')[-1]] = encode(img)\n",
    "    sys.stdout.write('\\r'+'Images encoded : '+str(a)+'/1000')\n",
    "    sys.stdout.flush()\n",
    "    a=a+1\n",
    "print(\"\\nTime taken in seconds =\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the bottleneck test features to disk\n",
    "with open(\"encoded_test_images.pkl\", \"wb\") as encoded_pickle:\n",
    "   dump(encoding_test, encoded_pickle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
